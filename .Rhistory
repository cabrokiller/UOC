geom_vline(xintercept = mn, color = "darkred") +
facet_wrap(~key, scales = "free") +
labs(title = "Valores de AIC y R2 segun el número de predictores empleado",
x = "Número de predictores", y = "valor") +
scale_color_tableau() +
theme_classic()
# Se crean las combinaciones de submodelos.
rs <-
regsubsets(log.RAI ~ ., ptrain[-1], nvmax = 12) %>%
summary()
n <- dim(ptrain)[1]
p <- length(rs$rss)
rs_crit <-
rs$which %>%
as_tibble() %>%
rowid_to_column() %>%
mutate(
rowid = factor(rowid),
rss = rs$rss,
r2_adj = rs$adjr2,
aic = n * log(rss/n) + (2:(p+1)) * 2)
# check minimo
mn <- ifelse(which.min(rs_crit$aic) == which.max(rs_crit$r2_adj), which.max(rs_crit$r2_adj), NA)
# Creamos el plot de AIC y R2
rs_crit %>%
select(rowid, r2_adj, aic) %>%
gather(key, value, -rowid) %>%
ggplot(aes(rowid, value, color = key, group = key)) +
geom_point() +
geom_line() +
geom_vline(xintercept = mn, color = "darkred") +
facet_wrap(~key, scales = "free") +
labs(title = "Valores de AIC y R2 segun el número de predictores empleado",
x = "Número de predictores", y = "valor") +
scale_color_tableau() +
theme_classic()
# modelo elegido
vars_aic <- rs$obj$xnames[rs$which[8,]]
vars_step <- colnames(model.matrix(mod_step))
pander(rbind(vars_aic, vars_step))
# modelo elegido
vars_aic_r2 <- rs$obj$xnames[rs$which[8,]]
pander(rbind(vars_aic_r2, vars_step))
pca_1 <-
ptrain %>%
select(S1:P5) %>%
FactoMineR::PCA(graph = F)
pander(t(pca_1$eig)[,1:8], digits = 2)
mod_pca <- pcr(log.RAI ~ ., data = ptrain[-1], validation = "CV", ncomp = 10)
plot(RMSEP(mod_pca, estimate = c("CV", "adjCV")))
ypred_pca_8 <- predict(mod_pca, ptest, ncomp=8)
rmse(ypred_pca_8, ptest$log.RAI)
ypred_pca_6 <- predict(mod_pca, ptest, ncomp=6)
rmse(ypred_pca_6, ptest$log.RAI)
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
pacman::p_load(knitr, faraway, broom, leaps, corrplot, pls, plsdepot, MASS, lars, pander, ggthemes, caret, betareg, gridExtra, tidyverse)
df <-
read_csv2("C_elegans.csv") %>%
mutate(p_reac = Perc_Reacting/100,
IndMutant = factor(IndMutant))
# boxplot de los datos
ggplot(df, aes(x = IndMutant, y = Perc_Reacting, color = IndMutant)) +
geom_boxplot() + labs(x="Grupo (No Mutante / Mutante)", y = "Porcentaje de reacción") +
geom_jitter(width = .3, shape = 4, alpha = .6) +
theme_classic() + scale_color_brewer(type = "qual", palette = 2)
mod_null <-
glm(IndMutant ~ 1, df, family = binomial(link = "logit"))
mod_log <-
glm(IndMutant ~ Perc_Reacting, df, family = binomial(link = "logit"))
summary(mod_log)
anova(mod_null, mod_log, test = "Chisq")
mod <- coin::independence_test(p_reac ~ IndMutant, df)
print(mod)
mod <- wilcox.test(Perc_Reacting ~ IndMutant, df)
pander(mod)
mod <- wilcox.test(Perc_Reacting ~ IndMutant, df)
pander(mod)
mod <- wilcox.test(Perc_Reacting ~ IndMutant, df, exact = F)
pander(mod)
mod <- wilcox.test(Perc_Reacting ~ IndMutant, df, exact = F)
pander(mod)
pca_1 <-
ptrain %>%
select(S1:P5) %>%
FactoMineR::PCA(graph = F)
pander(t(pca_1$eig)[,1:8], digits = 2)
pca_1 <-
ptrain %>%
select(S1:P5) %>%
FactoMineR::PCA(graph = F)
pander(t(pca_1$eig)[,1:8], digits = 2)
mod_pca <- pcr(log.RAI ~ ., data = ptrain[-1], validation = "CV", ncomp = 10)
plot(RMSEP(mod_pca, estimate = c("CV", "adjCV")))
ypred_pca_8 <- predict(mod_pca, ptest, ncomp=8)
rmse(ypred_pca_8, ptest$log.RAI)
ypred_pca_6 <- predict(mod_pca, ptest, ncomp=6)
rmse(ypred_pca_6, ptest$log.RAI)
mod_pca <- pcr(log.RAI ~ ., data = ptrain[-1], validation = "CV", ncomp = 10)
plot(RMSEP(mod_pca, estimate = c("CV", "adjCV")))
ypred_pca_8 <- predict(mod_pca, ptest, ncomp=8)
rmse(ypred_pca_8, ptest$log.RAI)
ypred_pca_6 <- predict(mod_pca, ptest, ncomp=6)
rmse(ypred_pca_6, ptest$log.RAI)
mod_plr <- plsr(log.RAI ~ ., data = ptrain[,-1], validation = "CV", ncomp = 10)
pls_reg <- plsdepot::plsreg1(ptrain[2:16], ptrain[17])
par(mfrow = c(1,2))
plot(RMSEP(mod_plr))
plot(pls_reg)
ypred_plr_3 <- predict(mod_pca, ptest, ncomp=3)
rmse(ypred_plr_3, ptest$log.RAI)
mod_plr <- plsr(log.RAI ~ ., data = ptrain[,-1], validation = "CV", ncomp = 10)
pls_reg <- plsdepot::plsreg1(ptrain[2:16], ptrain[17])
plot(RMSEP(mod_plr))
plot(pls_reg)
mod_plr
summary(mod_plr)
mod_plr$coefficients
mod_plr$Xtotvar
mod_plr$Xvar
mod_plr$Xvar[3]
mod_plr <- plsr(log.RAI ~ ., data = ptrain[,-1], validation = "CV", ncomp = 10)
pls_reg <- plsdepot::plsreg1(ptrain[2:16], ptrain[17])
# VAriablidad explicada por 3 componentes
mod_plr$Xvar[3]
plot(RMSEP(mod_plr))
plot(pls_reg)
mod_plrXvar
mod_plrXvar[3]
mod_plr$Xvar[3]
mod_plr$Xvar[3][]
mod_plr$Xvar[3][]
mod_plr$Xvar[3]
as.numeric(mod_plr$Xvar[3])
round(mod_plr$Xvar[3])
as.numeric(mod_plr$Xvar[3])
round(as.numeric(mod_plr$Xvar[3]), 2)
round(as.numeric(mod_plr$Xvar[3]), 1)
round(as.numeric(mod_plr$Xvar[3]), 2)
round(as.numeric(mod_plr$Xvar[3]), 1)
mod_plr$coefficients
mod_plr$scores
mod_plr$loadings
mod_plr$loading.weights
mod_plr$Yscores
mod_plr$projection
mod_plr$ncomp
mod_plr$Xmeans
mod_plr$validation
mod_plr$coefficients
mod_plr$scores
mod_plr$residuals
mod_plr$fitted.values
ypred_plr_3 <- predict(mod_pca, ptest, ncomp=3)
rmse(ypred_plr_3, ptest$log.RAI)
# Modelo Original
ypred_org <- predict(mod_org, newdata = ptest)
rmse(ypred_org, ptest$log.RAI)
# Modelo reducido `Stepwise`
ypred_step <- predict(mod_step, newdata = ptest)
rmse(ypred_step, ptest$log.RAI)
rmse(predict(mod_org), ptrain$log.RAI)
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI)
tibble(
entrenamiento = rmse(predict(mod_org), ptrain$log.RAI),
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI))
tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_org), ptrain$log.RAI),
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI))
tibble(
modelo = "stepwise",
entrenamiento = rmse(predict(mod_step), ptrain$log.RAI),
prueba = rmse(predict(mod_step, newdata = ptest), ptest$log.RAI)
)
tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_org), ptrain$log.RAI),
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI)
)
# Modelo reducido `stepwise`
tibble(
modelo = "stepwise",
entrenamiento = rmse(predict(mod_step), ptrain$log.RAI),
prueba = rmse(predict(mod_step, newdata = ptest), ptest$log.RAI)
)
# Modelo Original
tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_org), ptrain$log.RAI),
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI)
)
# Modelo reducido `stepwise`
tibble(
modelo = "stepwise",
entrenamiento = rmse(predict(mod_step), ptrain$log.RAI),
prueba = rmse(predict(mod_step, newdata = ptest), ptest$log.RAI)
)
get_rmse <- function(nom, modelo){
tibble(
modelo = nom,
entrenamiento = rmse(predict(modelo), ptrain$log.RAI),
prueba = rmse(predict(modelo, newdata = ptest), ptest$log.RAI)
)
}
mod_org
get_rmse("original", mod_org)
get_rmse <- function(nom, modelo){
tibble(
modelo = nom,
entrenamiento = rmse(predict(modelo), ptrain$log.RAI),
prueba = rmse(predict(modelo, newdata = ptest), ptest$log.RAI)
)
}
get_rmse("original", mod_org)
tibble(
modelo = nom,
entrenamiento = rmse(predict(mod), ptrain$log.RAI),
prueba = rmse(predict(mod, newdata = ptest), ptest$log.RAI)
)
get_rmse <- function(nom, mod){
tibble(
modelo = nom,
entrenamiento = rmse(predict(mod), ptrain$log.RAI),
prueba = rmse(predict(mod, newdata = ptest), ptest$log.RAI)
)
}
get_rmse("original", mod_org)
get_rmse("stepwise", mod_org)
get_rmse <- function(nom, mod){
tibble(
modelo = nom,
entrenamiento = rmse(predict(mod), ptrain$log.RAI),
prueba = rmse(predict(mod, newdata = ptest), ptest$log.RAI)
)
}
# Modelo Original
get_rmse("original", mod_org)
# Modelo reducido `stepwise`
get_rmse("stepwise", mod_org)
# Modelo reducido `stepwise`
get_rmse("stepwise", mod_step)
get_rmse <- function(nom, mod){
tibble(
modelo = nom,
entrenamiento = rmse(predict(mod), ptrain$log.RAI),
prueba = rmse(predict(mod, newdata = ptest), ptest$log.RAI)
)
}
# Modelo Original
get_rmse("original", mod_org)
# Modelo reducido `stepwise`
get_rmse("stepwise", mod_step)
# Modelo Original
tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_org), ptrain$log.RAI),
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI)
)
# Modelo reducido `stepwise`
tibble(
modelo = "stepwise",
entrenamiento = rmse(predict(mod_step), ptrain$log.RAI),
prueba = rmse(predict(mod_step, newdata = ptest), ptest$log.RAI)
)
# Modelo Original
(rmse_ org <-
# Modelo Original
(rmse_ org <- tibble(
# Modelo Original
(rmse_org <- tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_org), ptrain$log.RAI),
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI)
))
# Modelo Original
(rmse_org <- tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_org), ptrain$log.RAI),
prueba = rmse(predict(mod_org, newdata = ptest), ptest$log.RAI)
))
# Modelo reducido `stepwise`
(rmse_step <- tibble(
modelo = "stepwise",
entrenamiento = rmse(predict(mod_step), ptrain$log.RAI),
prueba = rmse(predict(mod_step, newdata = ptest), ptest$log.RAI)
))
(rmse_pca_8 <- tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_pca, ncomp=8), ptrain$log.RAI),
prueba = rmse(predict(mod_pca, ptest, ncomp=8), ptest$log.RAI)
))
# PCA con 8 componentes
ypred_pca_8 <- predict(mod_pca, ptest, ncomp=8)
rmse(ypred_pca_8, ptest$log.RAI)
(rmse_pca_8 <- tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_pca, ncomp=8), ptrain$log.RAI),
prueba = rmse(predict(mod_pca, ptest, ncomp=8), ptest$log.RAI)
))
(rmse_pca_6 <- tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_pca, ncomp=6), ptrain$log.RAI),
prueba = rmse(predict(mod_pca, ptest, ncomp=6), ptest$log.RAI)
))
# PCA con 8 componentes
(rmse_pca_8 <- tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_pca, ncomp=8), ptrain$log.RAI),
prueba = rmse(predict(mod_pca, ptest, ncomp=8), ptest$log.RAI)
))
# PCA con 6 componentes
(rmse_pca_6 <- tibble(
modelo = "original",
entrenamiento = rmse(predict(mod_pca, ncomp=6), ptrain$log.RAI),
prueba = rmse(predict(mod_pca, ptest, ncomp=6), ptest$log.RAI)
))
mod_plr <- plsr(log.RAI ~ ., data = ptrain[,-1], validation = "CV", ncomp = 10)
pls_reg <- plsdepot::plsreg1(ptrain[2:16], ptrain[17])
# VAriablidad explicada por 3 componentes
mod_plr$Xvar[3]
plot(RMSEP(mod_plr))
plot(pls_reg)
# PLS
rmse_pls <- tibble(
entrenamiento=rmse(predict(mod_plr, ncomp=3), ptrain$log.RAI),
test=rmse(predict(mod_plr, ptest, ncomp=3), ptest$log.RAI))
# PLS
(rmse_pls <- tibble(
entrenamiento=rmse(predict(mod_plr, ncomp=3), ptrain$log.RAI),
test=rmse(predict(mod_plr, ptest, ncomp=3), ptest$log.RAI)))
# PLS
(rmse_pls <- tibble(
modelo = "PLS",
entrenamiento=rmse(predict(mod_plr, ncomp=3), ptrain$log.RAI),
test=rmse(predict(mod_plr, ptest, ncomp=3), ptest$log.RAI)))
mod_rg <- lm.ridge(log.RAI ~ ., data = ptrain[,-1], lambda = seq(0.1, 10, .005))
lbd <-
tidy(mod_rg) %>%
distinct(lambda, GCV) %>%
rowid_to_column() %>%
top_n(1, -GCV)
# plot de los GCV
p1 <- tidy(mod_rg) %>%
ggplot(aes(lambda, GCV)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "red") +
theme_classic()
p2<- tidy(mod_rg) %>%
ggplot(aes(lambda, estimate, color = term)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "red") +
scale_colour_viridis_d() +
theme_classic()
grid.arrange(p1,p2,nrow = 1)
# hacemos la prediccion con el valor de lambda que minimiza GCV
ypred_rg <- cbind(1, as.matrix(ptest[2:16])) %*% coef(mod_rg)[lbd$rowid,]
# rendimiento del modelo
rmse(ypred_rg, ptest$log.RAI)
mod_rg <- lm.ridge(log.RAI ~ ., data = ptrain[,-1], lambda = seq(0.1, 10, .005))
lbd <-
tidy(mod_rg) %>%
distinct(lambda, GCV) %>%
rowid_to_column() %>%
top_n(1, -GCV)
# plot de los GCV
p1 <- tidy(mod_rg) %>%
ggplot(aes(lambda, GCV)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "red") +
theme_classic()
p2<- tidy(mod_rg) %>%
ggplot(aes(lambda, estimate, color = term)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "red") +
scale_colour_viridis_d() +
theme_classic()
grid.arrange(p1,p2,nrow = 1)
# Previa expermientacion definimos valores de lambda a graficar.
mod_rg <- lm.ridge(log.RAI ~ ., data = ptrain[,-1], lambda = seq(0.1, 10, .005))
lbd <-
tidy(mod_rg) %>%
distinct(lambda, GCV) %>%
rowid_to_column() %>%
top_n(1, -GCV)
p1 <- tidy(mod_rg) %>%
ggplot(aes(lambda, GCV)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "red") +
theme_classic()
p2<- tidy(mod_rg) %>%
ggplot(aes(lambda, estimate, color = term)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "red") +
scale_colour_viridis_d() +
theme_classic()
grid.arrange(p1,p2,nrow = 1)
p2<- tidy(mod_rg) %>%
ggplot(aes(lambda, estimate, color = term)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "darkred") +
scale_colour_tableau() +
theme_classic()
grid.arrange(p1,p2,nrow = 1)
# Previa expermientacion definimos valores de lambda a graficar.
mod_rg <- lm.ridge(log.RAI ~ ., data = ptrain[,-1], lambda = seq(0, 10, .005))
lbd <-
tidy(mod_rg) %>%
distinct(lambda, GCV) %>%
rowid_to_column() %>%
top_n(1, -GCV)
# plot de los GCV
p1 <- tidy(mod_rg) %>%
ggplot(aes(lambda, GCV)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "darkred") +
theme_classic()
p2<- tidy(mod_rg) %>%
ggplot(aes(lambda, estimate, color = term)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "darkred") +
scale_colour_tableau() +
theme_classic()
grid.arrange(p1,p2,nrow = 1)
p2<- tidy(mod_rg) %>%
ggplot(aes(lambda, estimate, color = term)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "darkred") +
scale_colour_viridis_d() +
theme_classic()
grid.arrange(p1,p2,nrow = 1)
# Previa expermientacion definimos valores de lambda a graficar.
mod_rg <- lm.ridge(log.RAI ~ ., data = ptrain[,-1], lambda = seq(0.01, 10, .005))
lbd <-
tidy(mod_rg) %>%
distinct(lambda, GCV) %>%
rowid_to_column() %>%
top_n(1, -GCV)
# plot de los GCV
p1 <- tidy(mod_rg) %>%
ggplot(aes(lambda, GCV)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "darkred") +
theme_classic()
p2<- tidy(mod_rg) %>%
ggplot(aes(lambda, estimate, color = term)) +
geom_line() +
geom_vline(xintercept = lbd$lambda, color = "darkred") +
scale_colour_viridis_d() +
theme_classic()
grid.arrange(p1,p2,nrow = 1)
ypred_rg_e <- cbind(1, as.matrix(ptrain[2:16])) %*% coef(mod_rg)[lbd$rowid,]
ypred_rg_t <- cbind(1, as.matrix(ptest[2:16])) %*% coef(mod_rg)[lbd$rowid,]
ypred_rg_e <- cbind(1, as.matrix(ptrain[2:16])) %*% coef(mod_rg)[lbd$rowid,]
ypres_e
ypred_e
ypred_rg_e
modelo = "Ridge R",
# rendimiento del modelo
rmse_rg <- tibble(
modelo = "Ridge R",
entrenamiento = rmse(ypred_e, ptrain$log.RAI),
test = rmse(ypred_rg, ptest$log.RAI))
# rendimiento del modelo
rmse_rg <- tibble(
modelo = "Ridge R",
entrenamiento = rmse(ypred_rg_e, ptrain$log.RAI),
test = rmse(ypred_rg, ptest$log.RAI))
# rendimiento del modelo
(rmse_rg <- tibble(
modelo = "Ridge R",
entrenamiento = rmse(ypred_rg_e, ptrain$log.RAI),
test = rmse(ypred_rg, ptest$log.RAI)))
mod_lar <- lars(as.matrix(ptrain[2:16]), ptrain$log.RAI)
mod_lar_cv <- cv.lars(as.matrix(ptrain[2:16]), ptrain$log.RAI)
summary(mod_lar)
plot(mod_lar)
mod_lar_cv <- cv.lars(as.matrix(ptrain[2:16]), ptrain$log.RAI)
mod_lar <- lars(as.matrix(ptrain[2:16]), ptrain$log.RAI)
mod_lar_cv <- cv.lars(as.matrix(ptrain[2:16]), ptrain$log.RAI)
plot(mod_lar)
mi_s <- mod_lar_cv$index[which.min(mod_lar_cv$cv)]
# minimzamos cv
mi_s <- mod_lar_cv$index[which.min(mod_lar_cv$cv)]
# minimzamos x cv
mi_s <- mod_lar_cv$index[which.min(mod_lar_cv$cv)]
ind <-
as_tibble(mod_lar_cv) %>%
top_n(1, -cv) %>%
pull(index)
```{r}
mod_lar <- lars(as.matrix(ptrain[2:16]), ptrain$log.RAI)
mod_lar_cv <- cv.lars(as.matrix(ptrain[2:16]), ptrain$log.RAI)
plot(mod_lar)
# minimzamos x cv
mi_s <- mod_lar_cv$index[which.min(mod_lar_cv$cv)]
ind <-
as_tibble(mod_lar_cv) %>%
top_n(1, -cv) %>%
pull(index)
predict(mod_lar, s = mi_s, type="coef", mode="fraction")$coef
ypred_lasso <- predict(mod_lar, ptest[2:16], s = 0.1, mode="fraction")$fit
rmse(ypred_lasso, ptest$log.RAI)
ypred_lasso_e <- predict(mod_lar, ptrain[2:16], s = 0.1, mode="fraction")$fit
rmse(ypred_lasso, ptest$log.RAI)
rmse(ypred_lasso_e, ptrain$log.RAI)
test = rmse(ypred_lasso, ptest$log.RAI))
modelo = "Lasso",
(rmse_lasso <- tibble(
modelo = "Lasso",
entrenamiento = rmse(ypred_lasso_e, ptrain$log.RAI),
test = rmse(ypred_lasso, ptest$log.RAI)))
lbd$lambda
